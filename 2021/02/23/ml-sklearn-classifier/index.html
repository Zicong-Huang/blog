<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zicong-huang.github.io","root":"/blog/","scheme":"Muse","version":"8.0.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}};
  </script>

  <meta name="description" content="MNIST 数据库导入MNIST数据库： 1234from sklearn.datasets import fetch_openmlmnist &#x3D; fetch_openml(&quot;mnist_784&quot;, version&#x3D;1)mnist.keys()">
<meta property="og:type" content="article">
<meta property="og:title" content="使用sklearn进行机器学习：Classification">
<meta property="og:url" content="https://zicong-huang.github.io/me.github.io/2021/02/23/ml-sklearn-classifier/index.html">
<meta property="og:site_name" content="ZICONG">
<meta property="og:description" content="MNIST 数据库导入MNIST数据库： 1234from sklearn.datasets import fetch_openmlmnist &#x3D; fetch_openml(&quot;mnist_784&quot;, version&#x3D;1)mnist.keys()">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://zicong-huang.github.io/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_8_0.jpg">
<meta property="og:image" content="https://zicong-huang.github.io/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_44_0.jpg">
<meta property="og:image" content="https://zicong-huang.github.io/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_46_0.jpg">
<meta property="og:image" content="https://zicong-huang.github.io/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_51_0.jpg">
<meta property="og:image" content="https://zicong-huang.github.io/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_70_0.jpg">
<meta property="og:image" content="https://zicong-huang.github.io/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_74_0.jpg">
<meta property="article:published_time" content="2021-02-23T21:13:20.000Z">
<meta property="article:modified_time" content="2021-02-23T22:29:07.113Z">
<meta property="article:author" content="黄梓聪">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="python">
<meta property="article:tag" content="sklearn">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zicong-huang.github.io/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_8_0.jpg">


<link rel="canonical" href="https://zicong-huang.github.io/me.github.io/2021/02/23/ml-sklearn-classifier/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>使用sklearn进行机器学习：Classification | ZICONG</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">ZICONG</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">梓聪的个人主页</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#MNIST-%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">1.</span> <span class="nav-text">MNIST 数据库</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AAbinary-classifier"><span class="nav-number">2.</span> <span class="nav-text">训练一个binary classifier</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Performance-Measures"><span class="nav-number">3.</span> <span class="nav-text">Performance Measures</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Measuring-accuracy-using-cross-validation"><span class="nav-number">3.1.</span> <span class="nav-text">Measuring accuracy using cross-validation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Confusion-Matrix"><span class="nav-number">3.2.</span> <span class="nav-text">Confusion Matrix</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Precision-Recall-Trade-off"><span class="nav-number">3.3.</span> <span class="nav-text">Precision&#x2F;Recall Trade-off</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-ROC-Curve"><span class="nav-number">3.4.</span> <span class="nav-text">The ROC Curve</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multi-class-Classification"><span class="nav-number">4.</span> <span class="nav-text">Multi-class Classification</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Error-Analysis"><span class="nav-number">5.</span> <span class="nav-text">Error Analysis</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multilabel-Classification"><span class="nav-number">6.</span> <span class="nav-text">Multilabel Classification</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multioutput-Classification"><span class="nav-number">7.</span> <span class="nav-text">Multioutput Classification</span></a></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">黄梓聪</p>
  <div class="site-description" itemprop="description">想法，笔记，以及实验</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives">
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blog/tags/">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </section>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zicong-huang.github.io/me.github.io/2021/02/23/ml-sklearn-classifier/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="黄梓聪">
      <meta itemprop="description" content="想法，笔记，以及实验">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZICONG">
    </span>

    
    
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          使用sklearn进行机器学习：Classification
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-02-23 16:13:20 / 修改时间：17:29:07" itemprop="dateCreated datePublished" datetime="2021-02-23T16:13:20-05:00">2021-02-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="MNIST-数据库"><a href="#MNIST-数据库" class="headerlink" title="MNIST 数据库"></a>MNIST 数据库</h2><p>导入MNIST数据库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_openml</span><br><span class="line"></span><br><span class="line">mnist = fetch_openml(<span class="string">&quot;mnist_784&quot;</span>, version=<span class="number">1</span>)</span><br><span class="line">mnist.keys()</span><br></pre></td></tr></table></figure>
<a id="more"></a>



<pre><code>dict_keys([&#39;data&#39;, &#39;target&#39;, &#39;frame&#39;, &#39;categories&#39;, &#39;feature_names&#39;, &#39;target_names&#39;, &#39;DESCR&#39;, &#39;details&#39;, &#39;url&#39;])
</code></pre>
<p>数据库关键字包括：</p>
<ul>
<li><code>DESCR</code>：   描述数据库</li>
<li><code>data</code>:     X数组，每行是一个instance，每列是一个feature</li>
<li><code>target</code>：  y数组</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = mnist[<span class="string">&quot;data&quot;</span>].to_numpy()</span><br><span class="line">y = mnist[<span class="string">&quot;target&quot;</span>].to_numpy()</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;x shape&quot;</span>, x.shape)</span><br><span class="line">print(<span class="string">&quot;y shape&quot;</span>, y.shape)</span><br></pre></td></tr></table></figure>
<pre><code>x shape (70000, 784)
y shape (70000,)
</code></pre>
<p>一共有784个features，每个features表示一个像素点的灰度，每幅图像有$28\times28$个像素。</p>
<p>下面查看其中一个instance。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">some_digit = x[<span class="number">0</span>]</span><br><span class="line">some_digit_image = some_digit.reshape(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line"></span><br><span class="line">plt.imshow(some_digit_image, cmap=<span class="string">&quot;binary&quot;</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_8_0.jpg" alt="jpg"></p>
<p>y是以字符串形式储存的，所以要转换为整数类型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">y = y.astype(np.<span class="built_in">int</span>)</span><br></pre></td></tr></table></figure>
<p>数据库已经预先“洗牌”并且划分好训练集（60,000）和测试集（10,000）:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_train, x_test = x[:<span class="number">60000</span>], x[<span class="number">60000</span>:]</span><br><span class="line">y_train, y_test = y[:<span class="number">60000</span>], y[<span class="number">60000</span>:]</span><br></pre></td></tr></table></figure>
<h2 id="训练一个binary-classifier"><a href="#训练一个binary-classifier" class="headerlink" title="训练一个binary classifier"></a>训练一个binary classifier</h2><p>以数字5为例，下面训练一个classifier，区分一个手写数字是5还是不是5。</p>
<p>创建一个关于数字是否是5的0/1向量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_train_5 = (y_train == <span class="number">5</span>)</span><br><span class="line">y_test_5 = (y_test == <span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>使用SGD classifier训练模型:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"></span><br><span class="line">sgd_clf = SGDClassifier()        <span class="comment"># random_state 相当于 seed</span></span><br><span class="line">sgd_clf.fit(x_train, y_train_5)</span><br></pre></td></tr></table></figure>



<pre><code>SGDClassifier()
</code></pre>
<p>Try this classifier on some numbers.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sgd_clf.predict([some_digit])</span><br></pre></td></tr></table></figure>



<pre><code>array([ True])
</code></pre>
<h2 id="Performance-Measures"><a href="#Performance-Measures" class="headerlink" title="Performance Measures"></a>Performance Measures</h2><h3 id="Measuring-accuracy-using-cross-validation"><a href="#Measuring-accuracy-using-cross-validation" class="headerlink" title="Measuring accuracy using cross-validation"></a>Measuring accuracy using cross-validation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br><span class="line">cross_val_score(sgd_clf, x_train, y_train_5, cv=<span class="number">3</span>, scoring=<span class="string">&quot;accuracy&quot;</span>)</span><br></pre></td></tr></table></figure>



<pre><code>array([0.957  , 0.96095, 0.96665])
</code></pre>
<p>因为这个classifier只区分数字是不是5，而数据集中5只占10%，所以一个总是猜5以外的数字的分类器也能得到90%的准确率 – 和我们训练好的classifier没有表现出多大差距。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Never5Classifier</span>(<span class="params">BaseEstimator</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    这个分类器不会做任何拟合的努力</span></span><br><span class="line"><span class="string">    这个分类器总是预测0</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, x, y=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.zeros((<span class="built_in">len</span>(x), <span class="number">1</span>), dtype=<span class="built_in">bool</span>)</span><br></pre></td></tr></table></figure>
<p>下面来看看<code>Never5Classifier</code>的准确度：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">never_5_clf = Never5Classifier()</span><br><span class="line">cross_val_score(never_5_clf, x_train, y_train_5, cv=<span class="number">3</span>, scoring=<span class="string">&quot;accuracy&quot;</span>)</span><br></pre></td></tr></table></figure>



<pre><code>array([0.91125, 0.90855, 0.90915])
</code></pre>
<p>因此，准确度一般<strong>不</strong>是对classifier最好的分类标准。特别是对于一个skewed datasets（一些类别出现的频率远高于另一些频率时）。在此处。非5出现的频率远高于5的频率。</p>
<h3 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict</span><br><span class="line"></span><br><span class="line">y_train_pred = cross_val_predict(sgd_clf, x_train, y_train_5, cv=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>This returns the predictions made on each test fold. This means that you get a clean prediction for each instance in the training set. “Clean” means that the prediction is made by a model that never saw the data during training.</p>
<p>Now get the confusion matrix.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">confusion_matrix(y_train_5, y_train_pred)</span><br></pre></td></tr></table></figure>



<pre><code>array([[53274,  1305],
       [ 1180,  4241]], dtype=int64)
</code></pre>
<p>Each row: an actual class.</p>
<p>Each col: a predicted class.</p>
<ul>
<li><p>第一行第一列：属于非5，并预测非5的个数 (True Negative,TN)</p>
</li>
<li><p>第一行第二列，属于非5. 并预测为5的个数 (False Positive,FP)</p>
</li>
<li><p>第二行第一列，属于5. 并预测非5的个数   (False Negative,FN)</p>
</li>
<li><p>第二行第二列，属于5，并预测为5的个数   (True Positive,TP)</p>
</li>
</ul>
<p>precision of the classifier: accuracy of the positive prediction:</p>
<p>$$<br>precision = \frac{TP}{TP+FP}<br>$$</p>
<p>recall, sensitivity or the true positive rate (TPR): ratio of positive instances that are correctly detected by the classifier:</p>
<p>$$<br>recall = \frac{TP}{TP+FN}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score, recall_score</span><br><span class="line"></span><br><span class="line">precision = precision_score(y_train_5, y_train_pred)</span><br><span class="line">recall = recall_score(y_train_5, y_train_pred)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Precision\t&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(precision))</span><br><span class="line">print(<span class="string">&quot;Recall\t\t&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(recall))</span><br></pre></td></tr></table></figure>
<pre><code>Precision    0.7647
Recall        0.7823
</code></pre>
<p>$F_1$ score: harmonic mean of precision and recall classifier. The harmonic mean gives much more weight to low values. As a result, the classifier will only get a high $F_1$ score if both recall and precision are high.</p>
<p>$$<br>\begin{align}<br>F_1 = \frac{2}{\frac{1}{precision} + \frac{1}{recall}}<br>    = 2 \times \frac{precision \times recall}{precision + recall}<br>    = \frac{TP}{TP + \frac{FN + FP}{2}}<br>\end{align}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"></span><br><span class="line">f1 = f1_score(y_train_5, y_train_pred)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;F1\t&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(f1))</span><br></pre></td></tr></table></figure>
<pre><code>F1    0.7734
</code></pre>
<h3 id="Precision-Recall-Trade-off"><a href="#Precision-Recall-Trade-off" class="headerlink" title="Precision/Recall Trade-off"></a>Precision/Recall Trade-off</h3><p>Sometimes want high precision even if low recall: </p>
<p>儿童视频过滤器 – 提高阳性判定准确率，尽管意味着会有更多阳性实例被错过。</p>
<p>Sometimes want high recall even if low precision:</p>
<p>安保报警器 – 提高阳性实例被找到的概率，尽管这意味着阳性判断准确率会下降。</p>
<p>事实上， precision 和 recall 会存在一个权衡取舍的关系。在分类时，提高阳性门槛，会提高precision，但是降低recall，相反，降低阳性门槛会提高recall，但是可以提高阳性门槛。下面是人为为预测设定门槛的方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># access the decision score that the classifier uses to make decision</span></span><br><span class="line">y_scores = sgd_clf.decision_function([some_digit])</span><br><span class="line">y_scores</span><br></pre></td></tr></table></figure>



<pre><code>array([1039.78028102])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">threshold = <span class="number">0</span></span><br><span class="line">y_some_digit_pred = (y_scores &gt; threshold)</span><br><span class="line">y_some_digit_pred</span><br></pre></td></tr></table></figure>



<pre><code>array([ True])
</code></pre>
<p>下面是选择threshold的方法。</p>
<p>首先，用<code>cross_val_predict()</code>函数获得所有训练集实例的预测值(clean)，但要求返回decision score而不是<code>True/False</code>的decision。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_scores = cross_val_predict(sgd_clf, x_train, y_train_5, cv=<span class="number">3</span>,</span><br><span class="line">                             method=<span class="string">&quot;decision_function&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>使用<code>precision_recall_curve</code>函数计算所有可能threshold的对应precision与recall。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve</span><br><span class="line"></span><br><span class="line">precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)</span><br></pre></td></tr></table></figure>
<p>使用<code>Matplotlib</code>作图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_precision_recall_vs_threshold</span>(<span class="params">precisions, recalls, thresholds</span>):</span></span><br><span class="line">    plt.plot(thresholds, precisions[:-<span class="number">1</span>], <span class="string">&quot;b--&quot;</span>, label=<span class="string">&quot;Precision&quot;</span>)</span><br><span class="line">    plt.plot(thresholds, recalls[:-<span class="number">1</span>], <span class="string">&quot;g-&quot;</span>, label=<span class="string">&quot;Recall&quot;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.xlabel(<span class="string">&quot;threshold&quot;</span>)</span><br><span class="line">    plt.ylim((<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">    plt.grid()</span><br><span class="line"></span><br><span class="line">plot_precision_recall_vs_threshold(precisions, recalls, thresholds)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_44_0.jpg" alt="jpg"></p>
<p>Precision在高threshold处呈现出一段bumpy的区间。这是因为，随着threshold的提高，能被认定阳性的案例减少，因而对于每一个错误都非常敏感。相反，在高threshold处，能被认定为阳性的案例已经很少了，再错漏一个不会有太大影响。</p>
<p>再分析在低threshold处，能被认定为阳性的案例很多，因此认错也多，再多认错一个敏感度不高，所以precision平滑；由于能被认定为阳性的案例很多，能找到的阳性基本都被找出来了，再少一个或者多一个，敏感度不大。</p>
<p>另一种方法：直接画出precision和recall的关系：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_precision_vs_recall</span>(<span class="params">precisions, recalls</span>):</span></span><br><span class="line">    plt.plot(recalls, precisions, <span class="string">&quot;b-&quot;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Recall&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;Precision&quot;</span>)</span><br><span class="line">    plt.xlim((<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">    plt.ylim((<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">    plt.grid()</span><br><span class="line">    </span><br><span class="line">plot_precision_vs_recall(precisions, recalls)</span><br></pre></td></tr></table></figure>

<p><img src="/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_46_0.jpg" alt="jpg"></p>
<p>假如想要90% precision</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">threshold_90_precision = thresholds[np.argmax(precisions &gt;= <span class="number">0.90</span>)]</span><br><span class="line">threshold_90_precision</span><br></pre></td></tr></table></figure>



<pre><code>3056.0585000597052
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_train_pred_90 = (y_scores &gt;= threshold_90_precision)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Precision\t&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(precision_score(y_train_5, y_train_pred_90)))</span><br><span class="line">print(<span class="string">&quot;Recall\t\t&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(recall_score(y_train_5, y_train_pred_90)))</span><br></pre></td></tr></table></figure>
<pre><code>Precision    0.9000
Recall        0.5562
</code></pre>
<h3 id="The-ROC-Curve"><a href="#The-ROC-Curve" class="headerlink" title="The ROC Curve"></a>The ROC Curve</h3><p>Receiver operating characteristics curve plots TPR against FPR. </p>
<p>TPR: True Positive Rate, or recall ratio – 在所有阳性案例中，识别出来阳性的比例。</p>
<p>$$<br>TPR = \frac{TP}{TP+FN}<br>$$</p>
<p>TNR: True Negative Rat, or specificity – 在所有阴性案例中，识别出来阴性的比例。</p>
<p>$$<br>TNR = \frac{TN}{TN+FP}<br>$$</p>
<p>FPR: False Positive Rate – 在所有阴性案例中，错误地识别出来阳性的比例（假阳性/所有阴性）</p>
<p>$$<br>FPR = 1-TNR<br>$$</p>
<p>所以ROC是sensitivity(recall) vs 1 - specificity – 真阳性/阳性 vs 假阳性/阴性</p>
<p>下面使用<code>roc_curve()</code>计算不同threshold下的TPR与FPR.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line"></span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_train_5, y_scores) <span class="comment"># y_scores: decision value</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_roc_curve</span>(<span class="params">fpr, tpr, label=<span class="literal">None</span></span>):</span></span><br><span class="line">    plt.plot(fpr, tpr, linewidth=<span class="number">2</span>, label=label)</span><br><span class="line">    plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">&#x27;k--&#x27;</span>) <span class="comment"># dashed diagonal</span></span><br><span class="line">    plt.xlim((<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">    plt.ylim((<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.xlabel(<span class="string">&quot;False Positive Rate&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;True Positive Rate&quot;</span>)</span><br><span class="line"></span><br><span class="line">plot_roc_curve(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_51_0.jpg" alt="jpg"></p>
<p>一个比较方法是比较AUC: area under the curve. 如果classifier是“完美的话”，FPR恒为0，TPR恒为1，AUC面积恒为1；如果classifier是随机的话，FPR = TPR，AUC面积接近0.5. 下面计算AUC。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;AUC: &#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(roc_auc_score(y_train_5, y_scores)))</span><br></pre></td></tr></table></figure>
<pre><code>AUC: 0.9604
</code></pre>
<p>如何选择Precision/recall (PR) curve或者AUC？</p>
<ul>
<li>PR: <ul>
<li>positive class is rare</li>
<li>care more about the false positives than the false negatives<br>（认定阳性时少出错）</li>
</ul>
</li>
<li>AUC:<ul>
<li>positive class is <strong>not</strong> rare</li>
<li>care more about the false negatives than the false positives<br>（尽量多地认出阳性）</li>
</ul>
</li>
</ul>
<h2 id="Multi-class-Classification"><a href="#Multi-class-Classification" class="headerlink" title="Multi-class Classification"></a>Multi-class Classification</h2><p>使用one-vs-one方法进行分类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sgd_clf.fit(x_train, y_train) <span class="comment"># 对所有类别进行分类</span></span><br><span class="line">sgd_clf.predict([some_digit]) <span class="comment"># 自动进行OvR的分类</span></span><br></pre></td></tr></table></figure>



<pre><code>array([5])
</code></pre>
<p>查看此实例对所有分类的decision value：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sgd_clf.decision_function([some_digit])</span><br></pre></td></tr></table></figure>



<pre><code>array([[-21024.40150978, -30404.40389192, -14057.76464372,
          1076.42126238, -24245.18237066,   3982.74400451,
        -21508.87615716, -14735.30165853,  -6727.9263852 ,
         -7748.15499922]])
</code></pre>
<p>交叉检验这个classifier的accuracy：分类正确的比例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cross_val_score(sgd_clf, x_train, y_train, cv=<span class="number">3</span>, scoring=<span class="string">&quot;accuracy&quot;</span>)</span><br></pre></td></tr></table></figure>



<pre><code>array([0.88775, 0.87555, 0.8795 ])
</code></pre>
<p>Scaling the inputs 可以提高accuracy.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">x_train_scaled = scaler.fit_transform(x_train.astype(np.float64))</span><br><span class="line"><span class="comment"># cross_val_score(sgd_clf, x_train_scaled, y_train, cv=3, scoring=&quot;accuracy&quot;)</span></span><br></pre></td></tr></table></figure>
<h2 id="Error-Analysis"><a href="#Error-Analysis" class="headerlink" title="Error Analysis"></a>Error Analysis</h2><p>假定已经获得一个最好的模型，现在想要提高这个模型。一个方法是分析它所犯的错误。</p>
<p>首先看它的confusion matrix。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_train_pred = cross_val_predict(sgd_clf, x_train, y_train, cv=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conf_mx = confusion_matrix(y_train, y_train_pred)</span><br><span class="line">conf_mx</span><br></pre></td></tr></table></figure>



<pre><code>array([[5637,    1,   32,   39,   11,   40,   37,    3,  104,   19],
       [   2, 6529,   25,   23,    7,   58,    5,   14,   69,   10],
       [  50,   92, 4909,  281,   51,   68,  106,   98,  277,   26],
       [  21,   38,  126, 5347,    5,  227,   11,   88,  193,   75],
       [  28,   32,   38,   30, 4757,   49,   84,   83,  179,  562],
       [  56,   23,   30,  327,   44, 4492,   82,   30,  261,   76],
       [  46,   27,   56,   60,   48,  234, 5311,    2,  126,    8],
       [  30,   32,   51,   54,   48,   38,    9, 5572,  108,  323],
       [  34,  160,   52,  241,   21,  415,   40,   40, 4727,  121],
       [  27,   20,   24,  100,  118,  124,    3,  220,  247, 5066]],
      dtype=int64)
</code></pre>
<p>利用灰度图可视化confusion matrix.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.matshow(conf_mx, cmap=plt.cm.gray)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_70_0.jpg" alt="jpg"></p>
<p>confusion matrix的每个元素都是instance的数量。现在把它标准化为比例。比如第二行第三列为把数字1（行）识别为数字2（列）的比例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">row_sums = conf_mx.<span class="built_in">sum</span>(axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">norm_conf_mx = conf_mx / row_sums</span><br></pre></td></tr></table></figure>
<p>把对角线元素都变为0，从而突出预测错误的情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.fill_diagonal(norm_conf_mx, <span class="number">0</span>)</span><br><span class="line">plt.matshow(norm_conf_mx, cmap=plt.cm.gray)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/blog/me.github/pics/2021-02-23-ml-sklearn-classifier/output_74_0.jpg" alt="jpg"></p>
<p>从图中可以看出，9经常被错误地认为是4，而4则往往能正确被识别出来。一个解决方法是针对性地收集更多“像4的9”，从而更好地训练模型分辨9和4。另外还有其他一些方法。</p>
<h2 id="Multilabel-Classification"><a href="#Multilabel-Classification" class="headerlink" title="Multilabel Classification"></a>Multilabel Classification</h2><p>指一个实例能分多个类的情况。</p>
<p>举例：创建一个classifier，给每个数据分配两个标签，第一个是大数与否（7， 8， 9属于大数），第二个是奇数与否。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">y_train_large = (y_train &gt;= <span class="number">7</span>)</span><br><span class="line">y_train_odd = (y_train % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line">y_multilabel = np.c_[y_train_large, y_train_odd]</span><br><span class="line"></span><br><span class="line">knn_clf = KNeighborsClassifier()</span><br><span class="line">knn_clf.fit(x_train, y_multilabel)</span><br></pre></td></tr></table></figure>



<pre><code>KNeighborsClassifier()
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn_clf.predict([some_digit])</span><br></pre></td></tr></table></figure>



<pre><code>array([[False,  True]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y_train_knn_pred = cross_val_predict(knn_clf, x_train, y_multilabel, cv=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">f1_score(y_multilabel, y_train_knn_pred, average=<span class="string">&quot;macro&quot;</span>)</span><br></pre></td></tr></table></figure>



<pre><code>0.976410265560605
</code></pre>
<h2 id="Multioutput-Classification"><a href="#Multioutput-Classification" class="headerlink" title="Multioutput Classification"></a>Multioutput Classification</h2><p>输出多个标签（分类）；每个标签可以取多个值（而非只有0与1）。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/blog/tags/python/" rel="tag"># python</a>
              <a href="/blog/tags/sklearn/" rel="tag"># sklearn</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/blog/2021/02/22/Sequential-List-in-C/" rel="prev" title="顺序线性表 —— C语言实现">
                  <i class="fa fa-chevron-left"></i> 顺序线性表 —— C语言实现
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
  
  
  



      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fas fa-h-square"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">黄梓聪</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
<script src="/blog/js/utils.js"></script><script src="/blog/js/motion.js"></script><script src="/blog/js/schemes/muse.js"></script><script src="/blog/js/next-boot.js"></script>

  















  








  

  

</body>
</html>
